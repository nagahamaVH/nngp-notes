---
title: "Poisson NNGP"
author: "Victor Hugo Nagahama"
date: '2022-10-25'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(dplyr)
library(mvtnorm)
```

In order to illustrate the estimation of NNGP for non-Gaussian responses in spatial data we will perform a simulation as follow

## Simulated data

\begin{align*}
  \boldsymbol{x} & \sim \mathcal{N} \left( \boldsymbol{0}, \boldsymbol{C}(\boldsymbol{\psi}) \right) \\
  y_i \mid \boldsymbol{x} & \overset{iid}\sim Poisson(\eta_i), \quad \eta_i = \exp x_i,
\end{align*}

\noindent
where the covariance matrix $C(\boldsymbol{\psi})$ is the Squared Exponential (SE) kernel in terms of signal variance and length-scale parameterization

\begin{equation*}
    \mathrm{Cov}(s_i, s_j) = \sigma^2 \exp \left\{ -\frac{(s_i - s_j)^2}{2 l^2} \right\}.
\end{equation*}

```{r}
n <- 500
m <- 3
set.seed(126)
coords <- cbind(runif(n), runif(n))

ord <- order(coords[,1])
coords <- coords[ord,]

sigma <- 1
l <- 1 / 2.3

d <- dist(coords) |>
  as.matrix()
C <- sigma^2 * exp(-d / (2 * l^2))
x <- rmvnorm(1, mean = rep(0, n), sigma = C) |>
  c()
eta <- exp(x)
y <- rpois(n, eta)
```

The code above simulate the presented data with latent field with covariance parameters $\sigma =$ `r sigma` and $l =$ `r round(l, 2)`.

```{r}
plot(d[,1], C[,1])
```

```{r}
# pi(x | y, theta) \propto pi(y | x, theta) * pi(x | theta)
posterior <- function(y, x, sigma_x, log = T) {
  eta <- exp(x)
  ll <- sum(dpois(y, eta, log = T)) + dmvnorm(x, sigma = sigma_x, log = T)
  if (!log) {
    ll <- exp(ll)
  }
  return(ll)
}

grad <- function(x, y) {
  y - exp(x)
}

hess <- function(x) {
  -exp(x)
}
```

## NNGP

```{r}
get_NN_ind <- function(ind, ind_distM_i, M){
  l <- ifelse(ind < M, ind, M)
  D_i <- rep(0, M);
  D_i[1:l] <- c(ind_distM_i[[ind]])[1:l]
  return(D_i)
}

get_nn <- function(coords, m){
  n <- nrow(coords)
  nn_data <- spNNGP::spConjNNGP(
    rep(0, n) ~ 1, coords = coords,
    n.neighbors = m,
    theta.alpha = c("phi" = 5, "alpha" = 0.5),
    sigma.sq.IG = c(2, 1),
    cov.model = "exponential",
    return.neighbor.info = T, fit.rep = F, 
    verbose = F)
  ord <- nn_data$neighbor.info$ord
  nn_idx <- sapply(1:(n - 1), get_NN_ind, nn_data$neighbor.info$n.indx[-1], m) |>
    t()
  
  return(list(ord = ord, nn_idx = nn_idx))
}

# Return L and D of (LDL) Cholesky decomposition of NNGP precision matrix
nngp_chol <- function(coords, m, p) {
  n <- nrow(coords)
  sigma <- p[1]
  l <- p[2]
  
  # Initialize A and dd = diag(D)
  A <- matrix(rep(0, n^2), n)
  dd <- c()
  dd[1] <- sigma^2
  
  # Cholesky
  nn_list <- get_nn(coords, m)
  # parallelize
  for (i in 1:(n - 1)) {
    nn <- nn_list$nn_idx[i, ]
    nn <- nn[nn != 0]
    d <- dist(coords[c(i + 1, nn),]) |>
      as.matrix()
    C <- sigma^2 * exp(-d / (2 * l^2))
    A[i + 1, nn] <- solve(C[-1, -1], C[-1, 1])
    dd[i + 1] <- C[1, 1] - C[1, -1] %*% A[i + 1, nn]
  }
  
  out <- list(
    L = diag(nrow = n) - A, 
    D = diag(dd)
  )

  return(out)
}
```

```{r}
# Laplace Approximation of pi(y | x)
la <- function(x0, y, Cinv, grad, hess, control = list(it = 100, tol = 1e-4)) {
  for (i in 1:control$it) {
    H <- diag(hess(x0), length(x0))
    grad <- grad(x0, y)

    # Covariance matrix of posterior
    Cx <- chol2inv(chol(Cinv - H))

    mu <- as.vector(Cx %*% (grad - H %*% x0))
    if (max(abs(x0 - mu)) < control$tol) break
    if (i == control$it) stop("Max iteraction number reached")
    x0 <- mu
  }

  parms <- list(mu = mu, sigma = Cx)
  return(parms)
}

# Estimating parameters
la_nngp <- function(y, coords, p0, x0, grad, hess) {
  print(exp(p0))

  # Vecchia Approx
  LD <- nngp_chol(coords, m, exp(p0))
  L <- LD$L
  D <- LD$D
  Cinv <- t(L) %*% (solve(D) %*% L)
  
  # Laplace Approximation
  gauss <- la(x0, y, Cinv, grad, hess)
  x_hat <- gauss$mu
  Cx <- gauss$sigma
  
  # Log-likelihood
  denom <- -(length(y) / 2) * log(2 * pi) - 0.5 * determinant(Cx)$modulus
  ll <- posterior(y, x_hat, C) - denom
  return(ll)
}
```

```{r check_la_nngp, eval = F}
p0 <- c(log(5), log(5))
x0 <- log(y + .5)

# debug(la_nngp)
# la_nngp(y, coords, p0, x0, grad, hess)
# undebug(la_nngp)

fitted_parms <- optim(
  p0, la_nngp, y = y, coords = coords, x0 = x0, grad = grad, hess = hess,
  method = "Nelder-Mead", hessian = T, control = list(fnscale = -1))

sigma_hat <- msm::deltamethod(
  list(~exp(x1), ~exp(x2)), fitted_parms$par, -solve(fitted_parms$hessian), ses = F)

confint2 <- function(mu, sigma, alpha = 0.05) {
  q <- qnorm(alpha / 2) %>% 
    abs()
  ub <- mu + q * sqrt(diag(sigma))
  lb <- mu - q * sqrt(diag(sigma))
  ci <- tibble(ub, lb, mu)
  return(ci)
}

ci_parms <- confint2(exp(fitted_parms$par), sigma_hat) %>%
  mutate(
    par = c("sigma", "l"),
    true = c(sigma, l)
  )

library(ggplot2)
ggplot(data = ci_parms, aes(x = "")) +
  facet_wrap(~par, scales = "free") +
  geom_linerange(aes(ymin = lb, ymax = ub)) +
  geom_point(aes(y = mu)) +
  geom_hline(aes(yintercept = true), lty = 2, col = "red") +
  labs(y = "Estimate", x = "")
```


```{r check_la, eval = F}
w_init <- log(y + .5)
fit_proxy <- la(w_init, y, C, gradient, hessian)

df_plot <- NULL
w_grid <- list()
h <- 0.05
for (i in 1:n) {
  se <- fit_proxy$sigma[i, i] %>%
    sqrt()
  w_grid[[i]] <- seq(fit_proxy$mu[i] - 3 * se, fit_proxy$mu[i] + 3 * se, by = h)
}

df_plot <- expand.grid(w_grid) |>
  as_tibble()
names(df_plot) <- paste0("w", 1:n)

unnorm_exact <- apply(df_plot, 1, posterior, y = y, sigma_x = C, log = F)
unnorm_proxy <- apply(df_plot, 1, dmvnorm, fit_proxy$mu, fit_proxy$sigma) 

df_plot <- df_plot %>%
  mutate(
    exact = unnorm_exact / sum(unnorm_exact * h^2),
    proxy = unnorm_proxy / sum(unnorm_proxy * h^2)
  )

library(ggplot2)
df_plot %>%
  tidyr::pivot_longer(cols = c(exact, proxy), names_to = "type", values_to = "density") %>%
  ggplot(., aes(x = w1, y = w2)) +
  geom_contour(aes(z = density)) +
  facet_wrap(vars(type)) +
  geom_point(aes(x = x[1], y = x[2]), pch = 3)
```

