---
title: "Gaussian NNGP"
author: "Victor Hugo Nagahama"
date: '2022-10-25'
output: html_document
editor_options: 
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(dplyr)
library(mvtnorm)
```

In order to illustrate the estimation of NNGP for Gaussian responses in spatial data we will perform a simulation as follow

## Simulated data

\begin{align*}
  \boldsymbol{x} & \sim \mathcal{N} \left( \boldsymbol{0}, \boldsymbol{C}(\boldsymbol{\psi}) \right) \\
  y_i \mid \boldsymbol{x} & \overset{iid}\sim Poisson(\eta_i), \quad \eta_i = \exp x_i,
\end{align*}

\noindent
where the covariance matrix $C(\boldsymbol{\psi})$ is the Squared Exponential (SE) kernel in terms of signal variance and length-scale parameterization

\begin{equation*}
  \mathrm{Cov}(s_i, s_j) = \sigma^2 \exp \left\{ -\frac{(s_i - s_j)^2}{2 l^2} \right\}.
\end{equation*}

```{r}
n <- 500
m <- 3
set.seed(126)
coords <- cbind(runif(n), runif(n))

ord <- order(coords[,1])
coords <- coords[ord,]

sigma <- 3
l <- 1 / 2.3
tau <- 1

d <- dist(coords) |>
  as.matrix()
C <- sigma^2 * exp(-d / (2 * l^2))
x <- rmvnorm(1, sigma = C) |>
  c()
eta <- x
y <- rnorm(n, eta, tau)
```

The code above simulate the presented data with latent field with covariance parameters $\sigma =$ `r sigma` and $l =$ `r round(l, 2)`.

```{r}
plot(d[,1], C[,1])
```

```{r}
# pi(x | y, theta) \propto pi(y | x, theta) * pi(x | theta)
posterior <- function(y, x, sigma_x, tau, log = T) {
  eta <- x
  ll <- sum(dnorm(y, eta, tau, log = T)) + dmvnorm(x, sigma = sigma_x, log = T)
  if (!log) {
    ll <- exp(ll)
  }
  return(ll)
}

grad <- function(x, y, tau) {
  1 / tau^2 * (y - x)
}

hess <- function(tau) {
  -1 / tau^2
}

```

## NNGP

```{r}
get_NN_ind <- function(ind, ind_distM_i, M){
  l <- ifelse(ind < M, ind, M)
  D_i <- rep(0, M);
  D_i[1:l] <- c(ind_distM_i[[ind]])[1:l]
  return(D_i)
}

get_nn <- function(coords, m){
  n <- dim(coords)[1]
  nn_data <- spNNGP::spConjNNGP(
    rep(0, n) ~ 1, coords = coords,
    n.neighbors = m,
    theta.alpha = c("phi" = 5, "alpha" = 0.5),
    sigma.sq.IG = c(2, 1),
    cov.model = "exponential",
    return.neighbor.info = T, fit.rep = F, 
    verbose = F)
  ord <- nn_data$neighbor.info$ord
  nn_idx <- sapply(1:(n - 1), get_NN_ind, nn_data$neighbor.info$n.indx[-1], m) |>
    t()
  
  return(list(ord = ord, nn_idx = nn_idx))
}

# Return L and D of (LDL) Cholesky decomposition of NNGP precision matrix
nngp_chol <- function(coords, m, p) {
  n <- dim(coords)[1]
  sigma <- p[1]
  l <- p[2]
  
  # Initialize A and dd = diag(D)
  A <- matrix(rep(0, n^2), n)
  dd <- c(sigma^2, rep(0, n - 1))
  
  # Cholesky
  nn_list <- get_nn(coords, m)
  # parallelize
  for (i in 1:(n - 1)) {
    nn <- nn_list$nn_idx[i, ]
    nn <- nn[nn != 0]
    d <- dist(coords[c(i + 1, nn),]) |>
      as.matrix()
    C <- sigma^2 * exp(-d / (2 * l^2))
    A[i + 1, nn] <- solve(C[-1, -1], C[-1, 1])
    dd[i + 1] <- C[1, 1] - C[1, -1] %*% A[i + 1, nn]
  }
  
  out <- list(
    L = diag(nrow = n) - A, 
    D = diag(dd)
  )
  
  return(out)
}
```

```{r}
# Laplace Approximation of pi(y | x)
la <- function(x0, y, Cinv, tau, grad, hess, control = list(it = 100, tol = 1e-4)) {
  for (i in 1:control$it) {
    H <- diag(hess(tau), length(x0))
    grad <- grad(x0, y, tau)
    
    # Covariance matrix of posterior
    Cx <- chol2inv(chol(Cinv - H))
    
    mu <- as.vector(Cx %*% (grad - H %*% x0))
    if (max(abs(x0 - mu)) < control$tol) break
    if (i == control$it) stop("Max iteraction number reached")
    x0 <- mu
  }
  
  parms <- list(mu = mu, sigma = Cx)
  return(parms)
}

# Estimating parameters
la_nngp <- function(y, coords, p0, x0, grad, hess) {
  print(exp(p0))
  tau <- exp(p0[3])

  # Vecchia Approx
  LD <- nngp_chol(coords, m, exp(p0[-3]))
  Cinv <- t(LD$L) %*% chol2inv(chol(LD$D)) %*% LD$L
  C <- chol2inv(chol(Cinv))

  # Laplace Approximation
  gauss <- la(x0, y, Cinv, tau, grad, hess)
  x_hat <- gauss$mu
  Cx <- gauss$sigma
  
  # Log-likelihood
  denom <- -(length(y) / 2) * log(2 * pi) - 0.5 * determinant(Cx)$modulus[1]
  ll <- posterior(y, x_hat, C, tau) - denom
  return(ll)
}
```

```{r check_la_nngp, eval = F}
p0 <- c(log(5), log(5), log(5))
x0 <- rep(0, n)

# debug(la_nngp)
# la_nngp(y, coords, p0, x0, grad, hess)
# undebug(la_nngp)

fitted_parms <- optim(
  p0, la_nngp, y = y, coords = coords, x0 = x0, grad = grad, hess = hess,
  method = "Nelder-Mead", hessian = T, control = list(fnscale = -1))

sigma_hat <- msm::deltamethod(
  list(~exp(x1), ~exp(x2), ~exp(x3)), fitted_parms$par, -solve(fitted_parms$hessian), ses = F)

confint2 <- function(mu, sigma, alpha = 0.05) {
  q <- qnorm(alpha / 2) %>% 
    abs()
  ub <- mu + q * sqrt(diag(sigma))
  lb <- mu - q * sqrt(diag(sigma))
  ci <- tibble(ub, lb, mu)
  return(ci)
}

ci_parms <- confint2(exp(fitted_parms$par), sigma_hat) %>%
  mutate(
    par = c("sigma", "l", "tau"),
    true = c(sigma, l, tau)
  )

library(ggplot2)
ggplot(data = ci_parms, aes(x = "")) +
  facet_wrap(~par, scales = "free") +
  geom_linerange(aes(ymin = lb, ymax = ub)) +
  geom_point(aes(y = mu)) +
  geom_hline(aes(yintercept = true), lty = 2, col = "red") +
  labs(y = "Estimate", x = "")
```

```{r check_la, eval = F}
w_init <- y
fit_proxy <- la(w_init, y, solve(C), tau, grad, hess)

df_plot <- NULL
w_grid <- list()
h <- 0.05
for (i in 1:n) {
  se <- fit_proxy$sigma[i, i] %>%
    sqrt()
  w_grid[[i]] <- seq(fit_proxy$mu[i] - 3 * se, fit_proxy$mu[i] + 3 * se, by = h)
}

df_plot <- expand.grid(w_grid) |>
  as_tibble()
names(df_plot) <- paste0("w", 1:n)

unnorm_exact <- apply(df_plot, 1, posterior, y = y, sigma_x = C, tau = tau, log = F)
unnorm_proxy <- apply(df_plot, 1, dmvnorm, fit_proxy$mu, fit_proxy$sigma) 

df_plot <- df_plot %>%
  mutate(
    exact = unnorm_exact / sum(unnorm_exact * h^2),
    proxy = unnorm_proxy / sum(unnorm_proxy * h^2)
  )

library(ggplot2)
df_plot %>%
  tidyr::pivot_longer(cols = c(exact, proxy), names_to = "type", values_to = "density") %>%
  ggplot(., aes(x = w1, y = w2)) +
  geom_contour(aes(z = density)) +
  facet_wrap(vars(type)) +
  geom_point(aes(x = x[1], y = x[2]), pch = 3)
```

```{r check_marginal_la}
w_init <- rep(0, n)
fit_proxy <- la(w_init, y, solve(C), tau, grad, hess)

h <- 0.01
n_sample <- 6
set.seed(52)
sampled <- sample(1:n, n_sample, replace = F)
plots <- list()
for (i in 1:n_sample) {
  id <- sampled[i]

  se <- fit_proxy$sigma[id, id] %>%
    sqrt()
  w_grid <- seq(fit_proxy$mu[id] - 3 * se, fit_proxy$mu[id] + 3 * se, by = h)
  
  df_plot <- rep(x, each = length(w_grid)) %>%
    matrix(ncol = n) %>%
    as_tibble(.name_repair = make.names)
  df_plot[,id] <- w_grid
  names(df_plot) <- paste0("w", 1:n)
  
  unnorm_exact <- apply(df_plot, 1, posterior, y = y, sigma_x = C, tau = tau, log = F)
  unnorm_proxy <- apply(df_plot, 1, dmvnorm, fit_proxy$mu, fit_proxy$sigma) 
  
  df_plot <- df_plot %>%
    mutate(
      exact = unnorm_exact / sum(unnorm_exact * h^2),
      proxy = unnorm_proxy / sum(unnorm_proxy * h^2)
    )

  p <- ggplot(df_plot, aes_string(x = paste0("w", id))) +
    geom_line(aes(y = exact)) +
    geom_line(aes(y = proxy), linetype = 2, col = "red") +
    geom_point(data = tibble(w = x[id]), aes(x = w, y = 0))
  plots[[i]] <- p
}

cowplot::plot_grid(plotlist = plots, nrow = 2)

plot(x, fit_proxy$mu); abline(a = 0, b = 1)
```

```{r check_sigma_hat}
parms_grid <- tibble(
  log_sigma = seq(.01, 50, by = 1),
  l = l,
  tau = tau
) %>%
  mutate_all(log)

# Assuming true parameters
w_init <- rep(0, n)

# ll <- apply(parms_grid, 1, gp_ll, coords = coords, y = y)

la_fit <- apply(
  parms_grid, 1, la_nngp, y = y, coords = coords, x0 = w_init, grad = grad, hess = hess)

# parms_grid <- parms_grid %>%
#   mutate(la, ll)
parms_grid <- parms_grid %>%
  mutate(la_fit)

parms_grid %>%
  filter(ll == max(ll)) %>%
  mutate(sigma = exp(log_sigma))

parms_grid %>%
  filter(la_fit == max(la_fit)) %>%
  mutate(sigma = exp(log_sigma))

ggplot(parms_grid, aes(x = log_sigma)) +
  # geom_line(aes(y = ll)) +
  geom_line(aes(y = la_fit), linetype = 2, color = "red")
```
